{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6f1fab1-f15a-427a-8ab3-829d0f8a742d",
   "metadata": {},
   "source": [
    "# Using Pipelines for Imputation and Scaling in Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b6005b8-9cd2-4be0-961c-445c1f06c023",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the transformed test set data the same: False\n",
      "Sum of differences between the two pipeline transformations: 44.06731100232763\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "## 載入數據集\n",
    "columns = [\"sex\", \"length\", \"diam\", \"height\", \"whole\", \"shucked\", \"viscera\", \"shell\", \"age\"]\n",
    "df = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\", names=columns)\n",
    "\n",
    "## 定義目標變數和預測變數\n",
    "y = df.age  # 目標變數 (age)\n",
    "X = df.drop(columns=['age'])  # 特徵變數 (排除 'age' 列)\n",
    "\n",
    "## 載入數值型和類別型特徵\n",
    "num_cols = X.select_dtypes(include=np.number).columns  # 數值型特徵\n",
    "cat_cols = X.select_dtypes(include=['object']).columns  # 類別型特徵\n",
    "\n",
    "## 模擬一些缺失值\n",
    "for i in range(1000):  # 隨機在特徵中引入缺失值\n",
    "    X.loc[np.random.choice(X.index), np.random.choice(X.columns)] = np.nan\n",
    "\n",
    "## 切分訓練集和測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25)\n",
    "\n",
    "#####-------使用 Pipeline 處理缺失值填補和標準化的代碼-----------------#####\n",
    "\n",
    "# 1. 使用 Pipeline 處理缺失值填補和數據標準化\n",
    "pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy='mean')),  # 使用平均值填補數值型特徵的缺失值\n",
    "    (\"scale\", StandardScaler())  # 對數值型特徵進行標準化\n",
    "])\n",
    "\n",
    "# 2. 在訓練集上擬合並轉換數據，然後在測試集上進行轉換\n",
    "pipeline.fit(x_train[num_cols])  # 在訓練集上擬合填補和標準化步驟\n",
    "x_transform = pipeline.transform(x_test[num_cols])  # 在測試集上轉換數據\n",
    "\n",
    "# 3. 使用 np.array_equal() 比較 Pipeline 轉換後的測試集與手動處理的結果是否相同\n",
    "array_diff = np.array_equal(x_transform, x_test_fill_missing_scale)\n",
    "print(\"Is the transformed test set data the same:\", array_diff)\n",
    "\n",
    "# 4. 改為使用中位數策略來填補缺失值\n",
    "pipeline_median = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy='median')),  # 使用中位數填補數值型特徵的缺失值\n",
    "    (\"scale\", StandardScaler())  # 仍然對數值型特徵進行標準化\n",
    "])\n",
    "\n",
    "# 5. 在使用中位數填補的 pipeline 上擬合並轉換數據\n",
    "pipeline_median.fit(x_train[num_cols])\n",
    "x_transform_median = pipeline_median.transform(x_test[num_cols])\n",
    "\n",
    "# 6. 比較兩個 pipeline 的結果差異\n",
    "# 計算兩個轉換結果的絕對差異的總和\n",
    "new_array_diff = abs(x_transform - x_transform_median).sum()\n",
    "print(\"Sum of differences between the two pipeline transformations:\", new_array_diff)\n",
    "\n",
    "#####-------處理過程解釋-----------------#####\n",
    "\n",
    "# 1. 在第一部分，我們使用了 `Pipeline` 來簡化流程，包括缺失值填補和標準化兩個步驟。\n",
    "#    - `SimpleImputer(strategy='mean')`: 填補數值型特徵中的缺失值，使用平均值進行填補。\n",
    "#    - `StandardScaler()`: 對數值型特徵進行標準化，將其變換為均值為 0，方差為 1 的數據。\n",
    "\n",
    "# 2. 然後，我們使用 `Pipeline.fit()` 在訓練數據上擬合變換器，並且使用 `Pipeline.transform()` 來變換測試數據。\n",
    "\n",
    "# 3. 之後，我們將轉換後的測試集數據與手動填補並標準化的數據進行比較，檢查是否一致。\n",
    "\n",
    "# 4. 接著，我們將 `SimpleImputer` 的填補策略從「均值」改為「中位數」，並進行相同的步驟。\n",
    "\n",
    "# 5. 最後，我們比較了兩個管道的結果差異，計算了轉換後的結果的絕對差異總和。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fa6b70-61d4-44bc-adc9-e7fd10e1209a",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Pipelines(Categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a87543e-34d1-49d5-9e7a-5aa8108bd3af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are the arrays equal?\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 載入資料集並定義欄位名稱\n",
    "columns = [\"sex\", \"length\", \"diam\", \"height\", \"whole\", \"shucked\", \"viscera\", \"shell\", \"age\"]\n",
    "df = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\", names=columns)\n",
    "\n",
    "# 定義目標變數y及預測變數X\n",
    "y = df.age\n",
    "X = df.drop(columns=['age'])\n",
    "\n",
    "# 找出數值型欄位及類別型欄位\n",
    "num_cols = X.select_dtypes(include=np.number).columns\n",
    "cat_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# 隨機插入缺失值\n",
    "for i in range(1000):\n",
    "    X.loc[np.random.choice(X.index), np.random.choice(X.columns)] = np.nan\n",
    "\n",
    "# 分割資料為訓練集與測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25)\n",
    "\n",
    "# 從訓練集中擷取類別型欄位\n",
    "x_train_cat = x_train[cat_cols]\n",
    "\n",
    "# 用類別型欄位的眾數來填補缺失值\n",
    "x_train_fill_missing = x_train_cat.fillna(x_train_cat.mode().values[0][0])\n",
    "\n",
    "# 對填補後的資料進行One-Hot編碼\n",
    "ohe = OneHotEncoder(sparse_output=False, drop='first').fit(x_train_fill_missing)\n",
    "# 轉換填補後的資料\n",
    "x_train_fill_missing_ohe = ohe.transform(x_train_fill_missing)\n",
    "\n",
    "# 針對測試集做相同處理\n",
    "x_test_fill_missing = x_test[cat_cols].fillna(x_train_cat.mode().values[0][0])\n",
    "x_test_fill_missing_ohe = ohe.transform(x_test_fill_missing)\n",
    "\n",
    "# 1. 使用Pipeline重構\n",
    "pipeline = Pipeline([(\"imputer\", SimpleImputer(strategy='most_frequent')), \n",
    "                     (\"ohe\", OneHotEncoder(sparse_output=False, drop='first'))])\n",
    "\n",
    "# 2. 擬合Pipeline並轉換測試資料（僅針對類別型欄位）\n",
    "pipeline.fit(x_train[cat_cols])\n",
    "x_transform = pipeline.transform(x_test[cat_cols])\n",
    "\n",
    "# 3. 使用np.array_equal()檢查兩個陣列是否相等\n",
    "check_arrays = np.array_equal(x_transform, x_test_fill_missing_ohe)\n",
    "\n",
    "# 顯示結果\n",
    "print('Are the arrays equal?')\n",
    "print(check_arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c6cd86-0209-4b06-8703-7e0b99bddc28",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Preprocessing with Pipelines and ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9592fe02-2ee3-49bc-9767-6ea734348d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "columns = [\"sex\",\"length\",\"diam\",\"height\",\"whole\",\"shucked\",\"viscera\",\"shell\",\"age\"]\n",
    "df = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\",names=columns)\n",
    "\n",
    "y = df.age  # 目標變數（年齡）\n",
    "X = df.drop(columns=['age'])  # 特徵變數（去掉年齡）\n",
    "num_cols = X.select_dtypes(include=np.number).columns  # 數值型欄位\n",
    "cat_cols = X.select_dtypes(include=['object']).columns  # 類別型欄位\n",
    "\n",
    "# 創建一些缺失值\n",
    "for i in range(1000):\n",
    "    X.loc[np.random.choice(X.index), np.random.choice(X.columns)] = np.nan\n",
    "\n",
    "# 訓練測試集劃分\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25)\n",
    "\n",
    "# 1. 創建一個處理數值型資料的pipeline `num_vals`\n",
    "num_vals = Pipeline([\n",
    "    (\"imputer\", SimpleImputer()),  # 用均值填補缺失值\n",
    "    (\"scale\", StandardScaler())    # 標準化數值資料\n",
    "])\n",
    "\n",
    "# 2. 創建一個處理類別型資料的pipeline `cat_vals`\n",
    "cat_vals = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy='most_frequent')),  # 用最頻繁的值填補缺失值\n",
    "    (\"ohe\", OneHotEncoder(drop='first', sparse_output=False))      # 用One-Hot Encoding處理類別資料\n",
    "])\n",
    "\n",
    "# 3. 創建一個ColumnTransformer `preprocess`，將數值型和類別型的處理步驟整合\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num_preprocess\", num_vals, num_cols),  # 處理數值型資料\n",
    "        (\"cat_preprocess\", cat_vals, cat_cols)   # 處理類別型資料\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 4. 擬合preprocess轉換器到訓練資料\n",
    "preprocess.fit(x_train)\n",
    "\n",
    "# 對測試資料進行轉換\n",
    "x_transform = preprocess.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366c3b50-5942-4658-9549-4701ba2b65f6",
   "metadata": {},
   "source": [
    "# Creating and Evaluating a Machine Learning Pipeline for Regression with Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da7cf880-ad95-4d70-a1db-beec574b7700",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49329870824922517\n",
      "0.49329870824922517\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 讀取數據並設定列名稱\n",
    "columns = [\"sex\",\"length\",\"diam\",\"height\",\"whole\",\"shucked\",\"viscera\",\"shell\",\"age\"]\n",
    "df = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\", names=columns)\n",
    "\n",
    "# 分離特徵 (X) 和標籤 (y)\n",
    "y = df.age\n",
    "X = df.drop(columns=['age'])\n",
    "\n",
    "# 獲取數值型和類別型特徵\n",
    "num_cols = X.select_dtypes(include=np.number).columns\n",
    "cat_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# 創建一些缺失值\n",
    "for i in range(1000):\n",
    "    X.loc[np.random.choice(X.index), np.random.choice(X.columns)] = np.nan\n",
    "\n",
    "# 分割數據集為訓練集和測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25)\n",
    "\n",
    "# 定義處理類別變量的管道 (填補缺失值並進行OneHot編碼)\n",
    "cat_vals = Pipeline([(\"imputer\", SimpleImputer(strategy='most_frequent')), \n",
    "                     (\"ohe\", OneHotEncoder(sparse_output=False, drop='first'))])\n",
    "\n",
    "# 定義處理數值變量的管道 (填補缺失值並標準化)\n",
    "num_vals = Pipeline([(\"imputer\", SimpleImputer(strategy='mean')), \n",
    "                     (\"scale\", StandardScaler())])\n",
    "\n",
    "# 創建列轉換器 (ColumnTransformer)，對數值和類別變量分別進行處理\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat_process\", cat_vals, cat_cols),\n",
    "        (\"num_process\", num_vals, num_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 1. 創建一個包含數據預處理和線性回歸模型的管道\n",
    "pipeline = Pipeline([(\"preprocess\", preprocess), \n",
    "                     (\"regr\", LinearRegression())])\n",
    "\n",
    "# 2. 用訓練數據擬合管道並對測試數據進行預測\n",
    "pipeline.fit(x_train, y_train)\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# 3. 計算並比較管道得分與預測結果的R-squared得分\n",
    "# 計算管道的得分\n",
    "pipeline_score = pipeline.score(x_test, y_test)\n",
    "print(pipeline_score)\n",
    "\n",
    "# 計算R-squared得分\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b02693e-d9b6-4695-b1c8-018c8b13a8a1",
   "metadata": {},
   "source": [
    "# Pipeline for Regression Models with Hyperparameter Tuning, Missing Value Imputation, and Scaling in Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "068ea24e-66b5-4dd2-bee4-0e55164fc2ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -5.476916937417327, Best parameters: {'regr': Lasso(alpha=0.01), 'regr__alpha': 0.01}\n",
      "The best regression model is:\n",
      "Lasso(alpha=0.01)\n",
      "The hyperparameters of the regression model are:\n",
      "{'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}\n",
      "The hyperparameters of the imputer are:\n",
      "{'add_indicator': False, 'copy': True, 'fill_value': None, 'keep_empty_features': False, 'missing_values': nan, 'strategy': 'most_frequent'}\n",
      "Transformation results match: False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import metrics\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# 讀取資料集並命名欄位\n",
    "columns = [\"sex\", \"length\", \"diam\", \"height\", \"whole\", \"shucked\", \"viscera\", \"shell\", \"age\"]\n",
    "df = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\", names=columns)\n",
    "\n",
    "# 分離特徵與標籤\n",
    "y = df.age\n",
    "X = df.drop(columns=['age'])\n",
    "\n",
    "# 數值型和類別型特徵的分離\n",
    "num_cols = X.select_dtypes(include=np.number).columns\n",
    "cat_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# 創建一些缺失值\n",
    "for i in range(1000):\n",
    "    X.loc[np.random.choice(X.index), np.random.choice(X.columns)] = np.nan\n",
    "\n",
    "# 訓練集與測試集的切割\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25)\n",
    "\n",
    "# 類別型數據的預處理流程（缺失值補全 + One-Hot編碼）\n",
    "cat_vals = Pipeline([(\"imputer\", SimpleImputer(strategy='most_frequent')),\n",
    "                     (\"ohe\", OneHotEncoder(sparse_output=False, drop='first'))])\n",
    "\n",
    "# 數值型數據的預處理流程（缺失值補全 + 標準化）\n",
    "num_vals = Pipeline([(\"imputer\", SimpleImputer(strategy='mean')), \n",
    "                     (\"scale\", StandardScaler())])\n",
    "\n",
    "# 綜合處理流程\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat_preprocess\", cat_vals, cat_cols),\n",
    "        (\"num_preprocess\", num_vals, num_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 創建管道：包括預處理步驟和回歸模型（線性回歸）\n",
    "pipeline = Pipeline([(\"preprocess\", preprocess), \n",
    "                     (\"regr\", LinearRegression())])\n",
    "\n",
    "# 超參數的搜尋範圍：包括不同回歸模型的選擇（LinearRegression, Ridge, Lasso）\n",
    "search_space = [{'regr': [LinearRegression()], 'regr__fit_intercept': [True, False]},\n",
    "                {'regr': [Ridge()], 'regr__alpha': [0.01, 0.1, 1, 10, 100]},\n",
    "                {'regr': [Lasso()], 'regr__alpha': [0.01, 0.1, 1, 10, 100]}]\n",
    "\n",
    "# GridSearchCV 進行交叉驗證，選擇最佳的模型和超參數\n",
    "gs = GridSearchCV(pipeline, search_space, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# 擬合訓練資料\n",
    "gs.fit(x_train, y_train)\n",
    "\n",
    "# 輸出最佳得分與最佳參數\n",
    "best_score = gs.best_score_\n",
    "best_params = gs.best_params_\n",
    "print(f\"Best score: {best_score}, Best parameters: {best_params}\")\n",
    "\n",
    "# 獲取最佳管道\n",
    "best_pipeline = gs.best_estimator_\n",
    "\n",
    "# 找出最佳的回歸模型\n",
    "best_regression_model = best_pipeline.named_steps['regr']\n",
    "print(\"The best regression model is:\")\n",
    "print(best_regression_model)\n",
    "\n",
    "# 獲取最佳回歸模型的超參數\n",
    "best_model_hyperparameters = best_regression_model.get_params()\n",
    "print(\"The hyperparameters of the regression model are:\")\n",
    "print(best_model_hyperparameters)\n",
    "\n",
    "# 取得類別型數據處理的超參數\n",
    "cat_preprocess_hyperparameters = best_pipeline.named_steps['preprocess'].named_transformers_['cat_preprocess'].named_steps['imputer'].get_params()\n",
    "print(\"The hyperparameters of the imputer are:\")\n",
    "print(cat_preprocess_hyperparameters)\n",
    "\n",
    "\n",
    "# 自定義的缺失值填充器類\n",
    "class MyImputer(BaseEstimator, TransformerMixin): \n",
    "    def __init__(self):\n",
    "        return None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.means = np.mean(X, axis=0)  # 計算每列的均值\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.means)  # 使用均值填充缺失值\n",
    "\n",
    "# 創建包含自定義缺失值填充器與標準化步驟的管道\n",
    "new_pipeline = Pipeline([(\"imputer\", MyImputer()), (\"scale\", StandardScaler())])\n",
    "\n",
    "# 在訓練集上擬合新管道（僅數值型特徵）\n",
    "new_pipeline.fit(x_train[num_cols])\n",
    "\n",
    "# 對測試集進行轉換\n",
    "x_transform = new_pipeline.transform(x_test[num_cols])\n",
    "\n",
    "# 檢查轉換後的結果是否與填充缺失值並標準化後的測試集結果相同\n",
    "check_arrays = np.array_equal(x_transform, x_test_fill_missing_scale)\n",
    "print(f\"Transformation results match: {check_arrays}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18321d6f-2210-4795-9927-1fc0d1e4ca48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "更新日期: 2024年12月01日\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "current_date = datetime.datetime.now().strftime(\"%Y年%m月%d日\")\n",
    "print(f\"更新日期: {current_date}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
