{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64de78b6-9d8a-446f-91bf-2bd5733d1806",
   "metadata": {},
   "source": [
    "# L1 Regularization(Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f846b6-2a04-444f-aecd-2566a2ffbfb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ 2.92335649 -0.         -0.         -0.          0.10261669]\n",
      "Intercept: 0.13717627314517145\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: 模擬數據集\n",
    "# 生成 100 個樣本，每個樣本有 5 個特徵\n",
    "X = np.random.randn(100, 5)  # 樣本特徵矩陣 (100x5)\n",
    "# 生成目標變數 y，其中僅第一個特徵對 y 有顯著貢獻\n",
    "# y = 3 * 第一個特徵 + 隨機噪聲\n",
    "y = X[:, 0] * 3 + np.random.randn(100)  # 增加隨機噪聲來模擬實際數據\n",
    "\n",
    "# Step 2: 初始化並訓練 Lasso 模型\n",
    "# alpha 是正則化參數，用來控制懲罰項的強度\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X, y)\n",
    "\n",
    "# Step 3: 輸出結果\n",
    "# 查看 Lasso 模型學習到的係數 (coefficients)\n",
    "# 非重要特徵的係數可能被壓縮為 0\n",
    "print(\"Coefficients:\", lasso.coef_)\n",
    "# 截距項，表示當所有特徵值為 0 時，目標變數的預測值\n",
    "print(\"Intercept:\", lasso.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d370db88-a0da-4a18-934f-768df9efa0b7",
   "metadata": {},
   "source": [
    "# L2 Regularization(Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f41b8a97-dd56-4271-95ad-3270841290b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ 2.99506969e+00 -2.01985894e+00 -7.25396330e-02 -5.88714865e-02\n",
      "  1.98790431e-03]\n",
      "Intercept: 0.0718301095239695\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: 模擬數據集\n",
    "# 生成 100 個樣本，每個樣本有 5 個特徵\n",
    "X = np.random.randn(100, 5)  # 樣本特徵矩陣 (100x5)\n",
    "# 生成目標變數 y，其中第一和第二個特徵對 y 有顯著貢獻\n",
    "# y = 3 * 第一個特徵 - 2 * 第二個特徵 + 隨機噪聲\n",
    "y = X[:, 0] * 3 + X[:, 1] * -2 + np.random.randn(100)  # 增加隨機噪聲來模擬實際數據\n",
    "\n",
    "# Step 2: 初始化並訓練 Ridge 模型\n",
    "# alpha 是正則化參數，用來控制懲罰項的強度\n",
    "ridge = Ridge(alpha=0.1)  # alpha 越大，正則化懲罰越強\n",
    "ridge.fit(X, y)\n",
    "\n",
    "# Step 3: 輸出結果\n",
    "# 查看 Ridge 模型學習到的係數 (coefficients)\n",
    "print(\"Coefficients:\", ridge.coef_)\n",
    "# 截距項，表示當所有特徵值為 0 時，目標變數的預測值\n",
    "print(\"Intercept:\", ridge.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f31ce0-c377-41a4-8071-dab67a13b580",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "Ideally we want a machine learning model to have low bias and low variance\n",
    "bias-variance tradeoff: rying to minimize bias and variance simultaneously is a bit of a conundrum as lowering one raises the other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cb7574-8416-4c3d-94d9-a50ffe4ef50a",
   "metadata": {},
   "source": [
    "# GridSearchCV\n",
    "GridSearchCV 是 Scikit-learn 中的一個工具，用於進行超參數的搜尋與交叉驗證。它的作用是遍歷指定的超參數組合，並通過交叉驗證來尋找最佳的超參數配置。這樣可以幫助我們選擇出最合適的模型，從而提高模型的預測精度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b773ac95-5666-4f4a-9443-4c801fa1cff6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression parameters: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Best model: LogisticRegression(C=10, max_iter=1000, penalty='l1', solver='liblinear')\n",
      "Best parameters: {'C': 10, 'penalty': 'l1'}\n",
      "Best score (train): 0.9671135430916552\n",
      "Test score: 0.951048951048951\n",
      "Grid search results:\n",
      "     C penalty     score\n",
      "0    1      l1  0.955349\n",
      "1    1      l2  0.952996\n",
      "2   10      l1  0.967114\n",
      "3   10      l2  0.957702\n",
      "4  100      l1  0.957674\n",
      "5  100      l2  0.962380\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Step 1: 載入乳腺癌數據集\n",
    "# `load_breast_cancer` 載入了關於乳腺癌的數據集\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# Step 2: 將數據集分割成訓練集和測試集\n",
    "# 訓練集和測試集的分配比率為 75% 訓練集，25% 測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=19)\n",
    "\n",
    "# Step 3: 初始化邏輯回歸模型和超參數範圍\n",
    "# `solver='liblinear'` 適用於小型數據集的求解器，`max_iter=1000` 設定最大迭代次數\n",
    "lr = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "\n",
    "# Step 4: 檢查 Logistic Regression 模型的默認參數\n",
    "# 顯示 Logistic Regression 模型的所有超參數設置\n",
    "print(\"Logistic Regression parameters:\", lr.get_params())\n",
    "\n",
    "# Step 5: 設定 GridSearchCV 進行超參數搜索\n",
    "# `penalty` 是正則化方法，可以選擇 'l1' 或 'l2'，`C` 是正則化強度的反比，數字越大正則化越弱\n",
    "parameters = {'penalty': ['l1', 'l2'], 'C': [1, 10, 100]}\n",
    "\n",
    "# Step 6: 設定 GridSearchCV 來進行超參數搜尋\n",
    "# `GridSearchCV` 用來進行超參數的遍歷搜尋，`cv=5` 表示使用 5 折交叉驗證\n",
    "clf = GridSearchCV(lr, parameters, cv=5)\n",
    "\n",
    "# Step 7: 在訓練數據上擬合 GridSearchCV 並找到最佳模型\n",
    "clf.fit(X_train, y_train)\n",
    "best_model = clf.best_estimator_  # 提取最佳模型\n",
    "print(\"Best model:\", best_model)  # 顯示最佳模型\n",
    "print(\"Best parameters:\", clf.best_params_)  # 顯示最佳超參數組合\n",
    "\n",
    "# Step 8: 計算最佳模型在訓練集和測試集上的表現\n",
    "best_score = clf.best_score_  # 最佳模型在交叉驗證中的平均得分\n",
    "test_score = clf.score(X_test, y_test)  # 測試集的得分\n",
    "print(\"Best score (train):\", best_score)  # 輸出最佳得分（訓練集）\n",
    "print(\"Test score:\", test_score)  # 輸出測試集得分\n",
    "\n",
    "# Step 9: 查看 GridSearchCV 搜索過程中的結果\n",
    "# 提取所有的超參數組合及其對應的測試分數\n",
    "hyperparameter_grid = pd.DataFrame(clf.cv_results_['params'])  # 提取超參數組合\n",
    "grid_scores = pd.DataFrame(clf.cv_results_['mean_test_score'], columns=['score'])  # 提取平均測試分數\n",
    "\n",
    "# 合併超參數和對應的分數，顯示每個超參數組合的結果\n",
    "df = pd.concat([hyperparameter_grid, grid_scores], axis=1)\n",
    "print(\"Grid search results:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69572273-0545-4df7-913c-4096d2db530f",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51990d68-d311-45a5-91a5-07ad12e28d20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: LogisticRegression(C=59.86584841970366, max_iter=1000, penalty='l1',\n",
      "                   solver='liblinear')\n",
      "Best Hyperparameters: {'C': 59.86584841970366, 'penalty': 'l1'}\n",
      "Best Training Score: 0.9692307692307693\n",
      "Test Score: 0.9824561403508771\n",
      "           C penalty     score\n",
      "0  37.454012      l1  0.967033\n",
      "1  18.343479      l2  0.960440\n",
      "2  59.865848      l1  0.969231\n",
      "3  44.583275      l1  0.964835\n",
      "4   5.808361      l2  0.960440\n",
      "5  33.370861      l2  0.962637\n",
      "6  70.807258      l2  0.962637\n",
      "7   5.641158      l2  0.958242\n",
      "First Draw: [98.99070216 35.15903074 85.29442762 39.32198395 81.63837489 68.27968736\n",
      " 46.83954012 12.53955994 24.19485092 89.81103592]\n",
      "Second Draw: [71.22041511 95.75982245  2.32827697 54.58696908  9.22251691 42.69351073\n",
      " 41.50600743 67.22382074 93.67144686 26.84879395]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer  # 載入乳腺癌數據集\n",
    "from sklearn.model_selection import train_test_split  # 載入訓練集與測試集的分割方法\n",
    "from sklearn.linear_model import LogisticRegression  # 載入邏輯回歸模型\n",
    "from sklearn.model_selection import RandomizedSearchCV  # 載入隨機搜索CV\n",
    "from scipy.stats import uniform  # 載入uniform分佈，用於隨機抽樣\n",
    "\n",
    "# 載入乳腺癌數據集\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# 將數據集分割為訓練集和測試集，80% 用於訓練，20% 用於測試\n",
    "X = cancer.data  # 特徵數據\n",
    "y = cancer.target  # 標籤數據\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # 進行分割\n",
    "\n",
    "# 定義要隨機搜索的超參數範圍\n",
    "# penalty 參數可以選擇 'l1' 或 'l2'，C 是正則化的強度\n",
    "distributions = {'penalty': ['l1', 'l2'], 'C': uniform(loc=0, scale=100)}  # C 在 0 到 100 之間均勻分佈\n",
    "\n",
    "# 初始化邏輯回歸模型，solver 設為 'liblinear' 以適應小型數據集，max_iter 設為 1000 防止迭代過少\n",
    "lr = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "\n",
    "# 初始化隨機搜索CV，使用定義的超參數範圍，n_iter 設為 8 代表隨機搜索 8 次\n",
    "clf = RandomizedSearchCV(lr, distributions, n_iter=8, random_state=42)\n",
    "\n",
    "# 進行隨機搜索並擬合訓練數據，找到最佳模型\n",
    "clf.fit(X_train, y_train)\n",
    "best_model = clf.best_estimator_  # 提取最佳模型\n",
    "print(\"Best Model:\", best_model)\n",
    "print(\"Best Hyperparameters:\", clf.best_params_)\n",
    "\n",
    "# 計算最佳模型在訓練集和測試集上的得分\n",
    "best_score = clf.best_score_  # 最佳訓練得分\n",
    "test_score = clf.score(X_test, y_test)  # 測試集得分\n",
    "print(\"Best Training Score:\", best_score)\n",
    "print(\"Test Score:\", test_score)\n",
    "\n",
    "# 查看隨機搜索的結果，提取所有的超參數組合及其對應的測試得分\n",
    "hyperparameter_values = pd.DataFrame(clf.cv_results_['params'])  # 提取超參數組合\n",
    "randomsearch_scores = pd.DataFrame(clf.cv_results_['mean_test_score'], columns=['score'])  # 提取平均測試分數\n",
    "\n",
    "# 合併超參數組合和分數，顯示每個超參數組合的結果\n",
    "df = pd.concat([hyperparameter_values, randomsearch_scores], axis=1)\n",
    "print(df)\n",
    "\n",
    "# 額外檢查 C 參數的隨機抽樣結果，查看其分佈情況\n",
    "first_draw = distributions['C'].rvs(10)  # 隨機抽取 10 個 C 的值\n",
    "second_draw = distributions['C'].rvs(10)  # 再隨機抽取 10 個 C 的值\n",
    "print(\"First Draw:\", first_draw)\n",
    "print(\"Second Draw:\", second_draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32f64725-ffcf-4c82-ae5e-554082145317",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "更新日期: 2024年12月01日\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "current_date = datetime.datetime.now().strftime(\"%Y年%m月%d日\")\n",
    "print(f\"更新日期: {current_date}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
